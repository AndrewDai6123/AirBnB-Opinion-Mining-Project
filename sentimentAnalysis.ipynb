{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load NLP Packages\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x1305e5dc0>),\n",
       " ('tagger', <spacy.pipeline.tagger.Tagger at 0x1305e5ca0>),\n",
       " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x1304f4eb0>),\n",
       " ('senter', <spacy.pipeline.senter.SentenceRecognizer at 0x1305e5a60>),\n",
       " ('attribute_ruler',\n",
       "  <spacy.pipeline.attributeruler.AttributeRuler at 0x13076c300>),\n",
       " ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x1308077c0>),\n",
       " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x1304f4e40>)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Explore Components of NLP pipeline\n",
    "#Method\n",
    "nlp.components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x1305e5dc0>),\n",
       " ('tagger', <spacy.pipeline.tagger.Tagger at 0x1305e5ca0>),\n",
       " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x1304f4eb0>),\n",
       " ('attribute_ruler',\n",
       "  <spacy.pipeline.attributeruler.AttributeRuler at 0x13076c300>),\n",
       " ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x1308077c0>),\n",
       " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x1304f4e40>)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Method 2\n",
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Spacy Textblob: Sentiment Analysis using Textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacytextblob.spacytextblob import SpacyTextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacytextblob.spacytextblob.SpacyTextBlob at 0x13222e2b0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding SpacyTextblob to NLP Pipeline\n",
    "nlp.add_pipe(\"spacytextblob\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x1305e5dc0>),\n",
       " ('tagger', <spacy.pipeline.tagger.Tagger at 0x1305e5ca0>),\n",
       " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x1304f4eb0>),\n",
       " ('senter', <spacy.pipeline.senter.SentenceRecognizer at 0x1305e5a60>),\n",
       " ('attribute_ruler',\n",
       "  <spacy.pipeline.attributeruler.AttributeRuler at 0x13076c300>),\n",
       " ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x1308077c0>),\n",
       " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x1304f4e40>),\n",
       " ('spacytextblob', <spacytextblob.spacytextblob.SpacyTextBlob at 0x13222e2b0>)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recheck our components\n",
    "nlp.components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x1305e5dc0>),\n",
       " ('tagger', <spacy.pipeline.tagger.Tagger at 0x1305e5ca0>),\n",
       " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x1304f4eb0>),\n",
       " ('attribute_ruler',\n",
       "  <spacy.pipeline.attributeruler.AttributeRuler at 0x13076c300>),\n",
       " ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x1308077c0>),\n",
       " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x1304f4e40>),\n",
       " ('spacytextblob', <spacytextblob.spacytextblob.SpacyTextBlob at 0x13222e2b0>)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recheck \n",
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytext = \"I love chocolate\"\n",
    "docx = nlp(mytext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check sentiment polarity\n",
    "docx._.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check sentiment subjectivity\n",
    "docx._.subjectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['love'], 0.5, 0.6, None)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check assessment: list polarity/subjectivity for the assessed token\n",
    "docx._.assessments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying Automation for Sentiment Analysis to all reviews:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be doing so with one list at a time for less running time and workload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"data/review/reviews_list1.csv\")\n",
    "\n",
    "#automate polarity for reviews2.csv\n",
    "def findSentiment():\n",
    "    for i, row in df.iterrows():\n",
    "        comments = str(df.at[i, 'Reviews'])\n",
    "        polarity = nlp(comments)._.polarity\n",
    "        '''\n",
    "        #test break\n",
    "        if i==8:\n",
    "            break\n",
    "        \n",
    "        '''\n",
    "        #if statement for pos/neg/na\n",
    "        if polarity > 0:\n",
    "            rating = \"positive\"\n",
    "        elif polarity < 0:\n",
    "            rating = \"negative\"\n",
    "        elif polarity == 0:\n",
    "            rating = \"NA\"\n",
    "        #add new column\n",
    "        df.at[i, 'Sentiment Rating'] = rating\n",
    "findSentiment()\n",
    "#export to new csv file\n",
    "df.to_csv('output CSV files/ratedReviews_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/review/reviews_list1_5.csv\")\n",
    "findSentiment()\n",
    "df.to_csv('output CSV files/ratedReviews_1_5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/review/reviews_list2.csv\")\n",
    "findSentiment()\n",
    "df.to_csv('output CSV files/ratedReviews_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/review/reviews_list3.csv\")\n",
    "findSentiment()\n",
    "df.to_csv('output CSV files/ratedReviews_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/review/reviews_list4.csv\")\n",
    "findSentiment()\n",
    "df.to_csv('output CSV files/ratedReviews_4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/review/reviews_list5.csv\")\n",
    "findSentiment()\n",
    "df.to_csv('output CSV files/ratedReviews_5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/review/reviews_list6.csv\")\n",
    "findSentiment()\n",
    "df.to_csv('output CSV files/ratedReviews_6.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/review/reviews_list7.csv\")\n",
    "findSentiment()\n",
    "df.to_csv('output CSV files/ratedReviews_7.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/review/reviews_list8.csv\")\n",
    "findSentiment()\n",
    "df.to_csv('output CSV files/ratedReviews_8.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/review/reviews_list9.csv\")\n",
    "findSentiment()\n",
    "df.to_csv('output CSV files/ratedReviews_9.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/review/reviews_list10.csv\")\n",
    "findSentiment()\n",
    "df.to_csv('output CSV files/ratedReviews_10.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the output dataframes with the sentimental analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "path = \"/Users/sanzi/Desktop/project/AirBnB-Opinion-Mining-Project/output CSV files/\"\n",
    "\n",
    "df1 = pd.read_csv(path + \"ratedReviews_1.csv\")\n",
    "df2 = pd.read_csv(path + \"ratedReviews_1_5.csv\")\n",
    "df3 = pd.read_csv(path + \"ratedReviews_2.csv\")\n",
    "df4 = pd.read_csv(path + \"ratedReviews_3.csv\")\n",
    "df5 = pd.read_csv(path + \"ratedReviews_4.csv\")\n",
    "df6 = pd.read_csv(path + \"ratedReviews_5.csv\")\n",
    "df7 = pd.read_csv(path + \"ratedReviews_6.csv\")\n",
    "df8 = pd.read_csv(path + \"ratedReviews_7.csv\")\n",
    "df9 = pd.read_csv(path + \"ratedReviews_8.csv\")\n",
    "df10 = pd.read_csv(path + \"ratedReviews_9.csv\")\n",
    "df11 = pd.read_csv(path + \"ratedReviews_10.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group counts and get the counts for each listing id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countAnalyis(df):\n",
    "        df_grouped = df.groupby(['listing_id','Sentiment Rating']).count()\n",
    "        id = df_grouped.index.unique().tolist()\n",
    "        rating = {}\n",
    "        count_review = 0\n",
    "\n",
    "        for i, row in df_grouped.iterrows():\n",
    "                \n",
    "                count_review = df_grouped.at[i, 'Reviews']\n",
    "                \n",
    "                listing_id_dict = i[0]\n",
    "                \n",
    "                review_type = i[1]\n",
    "        \n",
    "                #print(\"ID\")\n",
    "                #print(listing_id_dict)\n",
    "                \n",
    "                #print(\"Review\")\n",
    "                #print(review_type)\n",
    "                \n",
    "                #print(\"Count\")\n",
    "                #print(count_review)\n",
    "                \n",
    "                #print(\"-------\")\n",
    "\n",
    "                \n",
    "                #  the listing id is not in the dictionary\n",
    "        \n",
    "                if listing_id_dict not in rating:\n",
    "                        \n",
    "                        #print(\"The listing ID is not in the dictionary\")\n",
    "                        \n",
    "                        # Add the listing ID to the rating Dictionary with a list [0, 0, 0] : [P, Netural, Negative]\n",
    "                        \n",
    "                        rating[listing_id_dict] = [0, 0, 0]\n",
    "                        \n",
    "                        # The review type for this listing was Netural \n",
    "                        if review_type == \"NA\":\n",
    "                                #print(\"Review type for this is NA\")\n",
    "                                #print(count_review)\n",
    "                                rating.get(listing_id_dict)[1] = count_review\n",
    "\n",
    "                                        \n",
    "                        # The review type for this listing was Postive \n",
    "                        if review_type == \"positive\":\n",
    "                                #print(\"Review type for this is Postive\")\n",
    "                                #print(count_review)\n",
    "                                rating.get(listing_id_dict)[0] = count_review\n",
    "                        \n",
    "                                        \n",
    "                        # The review type for this listing was Negative \n",
    "                        if review_type == \"negative\":\n",
    "                                #print(\"Review type for this is Negative\")\n",
    "                                #print(count_review)\n",
    "                                rating.get(listing_id_dict)[2] = count_review\n",
    "                \n",
    "                # else the listing id is in the dictionary\n",
    "                else:\n",
    "                        # The review type for this listing was Netural \n",
    "                        if review_type == \"NA\":\n",
    "                                #print(\"Review type for this is NA\")\n",
    "                                #print(count_review)\n",
    "                                rating.get(listing_id_dict)[1] = count_review\n",
    "\n",
    "                                        \n",
    "                        # The review type for this listing was Postive \n",
    "                        if review_type == \"positive\":\n",
    "                                #print(\"Review type for this is Postive\")\n",
    "                                #print(count_review)\n",
    "                                rating.get(listing_id_dict)[0] = count_review\n",
    "                        \n",
    "                                        \n",
    "                        # The review type for this listing was Negative \n",
    "                        if review_type == \"negative\":\n",
    "                                #print(\"Review type for this is Negative\")\n",
    "                                #print(count_review)\n",
    "                                rating.get(listing_id_dict)[2] = count_review\n",
    "                        \n",
    "        return rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the rating dictonary into a dataframe with listing_id as rows and columns as description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = countAnalyis(df1)\n",
    "rating_df1 = pd.DataFrame({'Listing ID': list(rating.keys()), 'Description': list(rating.values())})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = countAnalyis(df2)\n",
    "rating_df2 = pd.DataFrame({'Listing ID': list(rating.keys()), 'Description': list(rating.values())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = countAnalyis(df3)\n",
    "rating_df3 = pd.DataFrame({'Listing ID': list(rating.keys()), 'Description': list(rating.values())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = countAnalyis(df4)\n",
    "rating_df4 = pd.DataFrame({'Listing ID': list(rating.keys()), 'Description': list(rating.values())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = countAnalyis(df5)\n",
    "rating_df5 = pd.DataFrame({'Listing ID': list(rating.keys()), 'Description': list(rating.values())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = countAnalyis(df6)\n",
    "rating_df6 = pd.DataFrame({'Listing ID': list(rating.keys()), 'Description': list(rating.values())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = countAnalyis(df7)\n",
    "rating_df7 = pd.DataFrame({'Listing ID': list(rating.keys()), 'Description': list(rating.values())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = countAnalyis(df8)\n",
    "rating_df8 = pd.DataFrame({'Listing ID': list(rating.keys()), 'Description': list(rating.values())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = countAnalyis(df9)\n",
    "rating_df9 = pd.DataFrame({'Listing ID': list(rating.keys()), 'Description': list(rating.values())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = countAnalyis(df10)\n",
    "rating_df10 = pd.DataFrame({'Listing ID': list(rating.keys()), 'Description': list(rating.values())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = countAnalyis(df11)\n",
    "rating_df11 = pd.DataFrame({'Listing ID': list(rating.keys()), 'Description': list(rating.values())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all the dataframes into one big dataframe\n",
    "frames = [rating_df1, rating_df2, rating_df3, \n",
    "          rating_df4, rating_df5, rating_df6,\n",
    "          rating_df7, rating_df8, rating_df9,\n",
    "          rating_df10, rating_df11]\n",
    "  \n",
    "result = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Listing ID</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2539</td>\n",
       "      <td>[8, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2595</td>\n",
       "      <td>[36, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5121</td>\n",
       "      <td>[47, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5136</td>\n",
       "      <td>[2, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5178</td>\n",
       "      <td>[390, 0, 11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7912</th>\n",
       "      <td>706487852182826405</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7913</th>\n",
       "      <td>706611147133623424</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7914</th>\n",
       "      <td>706712410572332671</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7915</th>\n",
       "      <td>706752921121143414</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7916</th>\n",
       "      <td>707272556257060819</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29759 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Listing ID   Description\n",
       "0                   2539     [8, 0, 0]\n",
       "1                   2595    [36, 0, 0]\n",
       "2                   5121    [47, 0, 0]\n",
       "3                   5136     [2, 0, 0]\n",
       "4                   5178  [390, 0, 11]\n",
       "...                  ...           ...\n",
       "7912  706487852182826405     [1, 0, 0]\n",
       "7913  706611147133623424     [1, 0, 0]\n",
       "7914  706712410572332671     [1, 0, 0]\n",
       "7915  706752921121143414     [1, 0, 0]\n",
       "7916  707272556257060819     [1, 0, 0]\n",
       "\n",
       "[29759 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the Dataframe into the CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(\"/Users/sanzi/Desktop/project/AirBnB-Opinion-Mining-Project/output CSV files/Sentimental_Count.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge listings.csv and Sentimental_Count.csv dataframes by an Inner Join.\n",
    "\n",
    "It will merge both dataframes based on the specified column and then return new dataframe containing only those rows that have a matching value in both original dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# reading two csv files\n",
    "data1 = pd.read_csv('data/listings.csv')\n",
    "data2 = pd.read_csv('output CSV files/Sentimental_Count.csv')\n",
    "\n",
    "# renaming column on data1 to match data2\n",
    "data1.rename(columns={'id': 'Listing ID'}, inplace=True)\n",
    "data1.set_index('Listing ID').to_csv(\"output CSV files/listingsRenameID.csv\")\n",
    "\n",
    "# using merge function by setting how='inner'\n",
    "data3 = pd.read_csv('output CSV files/listingsRenameID.csv')\n",
    "output = pd.merge(data3, data2, \n",
    "                   on='Listing ID', \n",
    "                   how='inner')\n",
    "  \n",
    "# output result\n",
    "output.to_csv('C:/Users/Hello/Documents/GitHub/AirBnB-Opinion-Mining-Project/output CSV files/merged.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the CSV Dataframe into GeoJSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from geopandas import GeoSeries, GeoDataFrame\n",
    "from shapely import wkt\n",
    "\n",
    "#Read new geocoded CSV file\n",
    "d = pd.read_csv('output CSV files/merged.csv')\n",
    "\n",
    "#CSV to geoJSON\n",
    "df = pd.DataFrame(d)\n",
    "gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.longitude, df.latitude), crs=\"EPSG:4326\")\n",
    "gdf.to_file(filename='output geoJSON files/listingsRated.geojson', driver=\"GeoJSON\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7a58e131ee068f189d8d79a6f196862ecf2f1295c59f9b998dcbd6fe095dc999"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
